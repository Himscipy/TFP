activation:<function relu at 0x10da38048>
layer_sizes:[100, 50, 10]
learning_rate:0.001
training_epochs:1
batch_size:100
num_monte_carlo:2
num_monte_carlo_test:100
seed:19931028
keep_prob:0.8
isdrop:False
drop_pattern:c
regularizer:0.0
KLscale:1
inshape:[32, 32, 3]
repeatConv:1
priorstd:1
trial:try
data:cifar10
model:bnn
viz_steps:400
