activation:<function relu at 0x1164c5f28>
layer_sizes:[100, 50, 10]
learning_rate:0.001
training_epochs:16
num_iters:0
batch_size:100
num_monte_carlo:1
num_monte_carlo_test:128
seed:19931028
keep_prob:0.8
isdrop:False
drop_pattern:c
regularizer:0.0
KLscale:1
inshape:[32, 32, 3]
repeatConv:1
priorstd:1
trial:20180913
data:mnist
model:bnn
viz_steps:2000
