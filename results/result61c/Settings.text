activation:<function relu at 0x7f52b3a87f28>
priorstd:1
batch_size:100
drop_pattern:c
data:cifar10
poststd:0.01
learning_rate:0.001
inshape:[32, 32, 3]
repeatConv:2
model:bnn
training_epochs:20
KLscale:0.4
num_monte_carlo:20
layer_sizes:[100, 50, 10]
keep_prob:0.8
seed:19931028
trial:61c
isdrop:False
