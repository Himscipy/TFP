priorstd:1
activation:<function relu at 0x2aab4a8d7510>
KLscale:1.0
regularizer:0.0
learning_rate:0.001
model:bnn
training_epochs:20
batch_size:100
inshape:[32, 32, 3]
repeatConv:2
seed:19931028
layer_sizes:[100, 50, 10]
drop_pattern:c
poststd:0.1
num_monte_carlo:20
data:cifar10
trial:83c
keep_prob:0.8
isdrop:False
